---
output:
  pdf_document:
    includes:
      before_body: beforebody.tex
      in_header: header.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, fig.align = "center", 
                      warning = FALSE, message = FALSE)
library(tidyverse)
library(broom)
library(knitr)

theme_set(theme_bw())

load("../../cache/df.spam.RData")
load("../../cache/df.spam.tidy.RData")
load("../../cache/tab.spam.rsparse.RData")
df.eda <- tab.spam.rsparse
```

\newpage\leavevmode\thispagestyle{empty}\newpage

\tableofcontents

\newpage\leavevmode\newpage





\section{Introducción}


Este trabajo presenta el análisis realizado 
para obtener la predicción de spam en un conjunto de 
correos electrónicos. Se presentan técnicas de 
aprendizaje supervisado y no supervisado 
vistas en el curso de Aprendizaje Estadístico, así como,
técnicas usadas para minería de texto. 


El documento inicia con una sección donde
se explica el procesamiento del texto 
realizado donde
se definen variables y medidas necesarias para 
el análisis.
Posteriormente se presenta el análisis exploratorio 
de las variables extraídas del texto.
En la siguiente sección se muestran diferentes algoritmos para 
la predicción de spam, entre ellos,
Naive Bayes, Regresión Logística y
Máquinas de Soporte Vectorial. 
En la sección siguiente se presenta el análisis 
de selección de modelo considerando los resultados de la 
implementación de modelos.
Finalmente, en las dos secciones siguientes
se presentan los resultados y conclusiones
del trabajo.


Los datos usados en este proyecto 
contiene el texto de `r nrow(df.spam)` emails 
etiquetados como spam y no spam. A continuación se 
presentan un ejemplo de texto por cada etiqueta. 

\paragraph{Email etiquetado como spam}

> \color{gray}{Subject: would you like a  250 gas card ?  don ' t let the current 
high price of gas get to you .  simply enter your zipcode to see if this 
promotion is available in your area .  ubycvski}

\paragraph{Email etiquetado como no spam}
> \color{gray}{Subject: trading limit and policy changes  vince -  here ' s 
a summary of what ' s going to the bod , along with updated policy . feel  
free to call me if you have any questions .  regards ,  cassandra .}

\bigskip

En la siguiente sección se profundiza sobre
el contenido de los datos y se presenta 
una breve explicación del 
preprocesamiento realizado. 


\section{Procesamiento del Texto}

El cuerpo de trabajo que se usó en el proyecto 
proviene del texto de cada correo electrónico. Para poder
realizar el modelo predictivo, previemente se usaron 
técnicas de minería de texto. En primer lugar
se realizó la tokenización del cuerpo de texto, es decir, 
se separo el cuerpo por palabras y
se elminaron números, *stop words*\footnote{Lista de palabras
en inglés del proyecto de stemmatización Snowball de
<http://snowball.tartarus.org/algorithms/english/stop.txt>.}
y signos de puntuación. 

Tomando los ejemplos de emails de la sección anterior, 
a continuación 
se muestra el resultado después de la tokenización.
Cada renglón representa una palabra relacionada a un 
documento o email con una etiqueta asignada de spam.
Únicamente se imprimen las primeras cinco palabras.

\paragraph{Email etiquetado como spam}

> \color{gray}{Subject: would you like a  250 gas card ?  don ' t let the current 
high price of gas get to you .  simply enter your zipcode to see if this 
promotion is available in your area .  ubycvski}

```{r}
df.spam.tidy %>% 
  filter(document == "1365") %>% 
  head %>% 
  knitr::kable(align = "rcl")
```



\paragraph{Email etiquetado como no spam}

> \color{gray}{Subject: trading limit and policy changes  vince -  here ' s 
a summary of what ' s going to the bod , along with updated policy . feel  
free to call me if you have any questions .  regards ,  cassandra .}

```{r}
df.spam.tidy %>% 
  filter(document == "1386") %>% 
  head %>% 
  knitr::kable(align = "rcl")
```

Considerando estos filtros se tienen `r df.spam.tidy$word %>% n_distinct()`
palabras. 
El siguiente filtro que se aplicó fue eliminar el 5% de términos 
escasos (*sparse*). Después de este filtro el número de palabras se 
reduce a `r tab.spam.rsparse$term %>% n_distinct()` que son las palabras
con las que se realizará el análisis.

El siguiente paso importante es la construcción del
valor numérico
**term-frequency-inverse-document- frequency** (tf-idf) que
refleja la *importancia* de cada palabra para el documento/email en
una colección de corpus o conjunto de correos. Generalmente es usada
como un factor de ponderación por que valora la proporción de veces
que la palabra aparece en el documento pero penaliza por la 
frecuencia con la que aparece en el corpus, lo que permite ajustar
el hecho de que algunas palabras se usan com mayor frecuencia. 
En la actualidad esta medida es uno 
de los esquemas de ponderación de términos más populares.

Finalmente, con la base de datos de palabras resultante y 
la variable tf-idf se construye la matriz de documento por 
término (*document-term matrix*).
Considerando la estructura y los filtros presentados previamente, 
en la siguiente sección se presenta un análisis exploratorio de los datos. 





\section{Análisis Exploratorio}


En esta sección se explorará el comportamiento de los
`r nrow(df.spam)` documentos en general y por cada etiqueta
asociado a los términos seleccionados en el 
proceso anterior. 

Una característica importante de los datos es el desbalance
que existe entre las etiquetas. El número de correos 
identificados como spam es igual a 
`r filter(df.spam, spam == 1)$spam %>% length()`, lo que 
corresponde al 
`r round(100*length(filter(df.spam, spam == 1)$spam)/nrow(df.spam))`% 
de las observiaciones. Esto es relevante ya que al 
momento de modelar es necesario considerar esto. 



```{r}
df.eda %>% 
  group_by(document, spam) %>% 
  dplyr::summarise(n_words = sum(count)) %>% 
  ungroup %>% 
  .$n_words %>% 
  summary() %>% 
  tidy() %>% t %>% 
  data.frame() %>% 
  rownames_to_column("Número de palabras") %>% 
  knitr::kable(digits = 0, align = "rc")
```



```{r}
df.eda %>% 
  group_by(document, spam) %>% 
  dplyr::summarise(n_words = sum(count)) %>% 
  ungroup %>% 
  group_by(spam) %>% 
  dplyr::summarise(`promedio palabras` = mean(n_words)) %>% 
  ungroup() %>% 
  knitr::kable(align = "rl", digits = c(0,0))
```





```{r, out.width='80%'}
knitr::include_graphics("../../graphs/eda/01_tfidf_hist.png")
```





\subsection{Frecuencia de Términos}


```{r, out.width='90%'}
knitr::include_graphics("../../graphs/eda/02_wc_freq.png")
```

```{r, out.width='90%'}
knitr::include_graphics("../../graphs/eda/02_wc_tfidf.png")
```



\subsection{Asociación entre Términos}


```{r, out.width='90%'}
knitr::include_graphics("../../graphs/eda/03_hclust_terms_total.png")
```

```{r, out.width='90%'}
knitr::include_graphics("../../graphs/eda/03_hclust_terms_spam.png")
```

```{r, out.width='90%'}
knitr::include_graphics("../../graphs/eda/03_hclust_terms_nospam.png")
```



\section{Modelos Predictivos}

\subsection{Bayes Ingenuo NB}

\subsection{Regresión Logística}

\subsection{Máquinas de Soporte Vectorial}

\subsection{Red Bayesiana}


\section{Selección de Modelos}

\section{Resultados}

\section{Conclusiones}



\section{Referencias}

